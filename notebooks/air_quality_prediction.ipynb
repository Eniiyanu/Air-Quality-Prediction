{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Zindi Air Quality Prediction from Low-Cost IoT devices Contest**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1: Load and Explore Data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>MQ7_analog</th>\n",
       "      <th>MQ9_analog</th>\n",
       "      <th>MG811_analog</th>\n",
       "      <th>MQ135_analog</th>\n",
       "      <th>device_name</th>\n",
       "      <th>CO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_000001</td>\n",
       "      <td>28.975</td>\n",
       "      <td>74.475</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>3476.5</td>\n",
       "      <td>1572.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>585.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_000002</td>\n",
       "      <td>31.900</td>\n",
       "      <td>66.500</td>\n",
       "      <td>3813.0</td>\n",
       "      <td>2726.0</td>\n",
       "      <td>4145.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>613.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_000003</td>\n",
       "      <td>31.675</td>\n",
       "      <td>60.015</td>\n",
       "      <td>2811.0</td>\n",
       "      <td>1563.5</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>2708.5</td>\n",
       "      <td>alpha</td>\n",
       "      <td>616.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_000004</td>\n",
       "      <td>31.580</td>\n",
       "      <td>59.220</td>\n",
       "      <td>2844.0</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>4310.0</td>\n",
       "      <td>2723.0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>642.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_000005</td>\n",
       "      <td>31.690</td>\n",
       "      <td>62.030</td>\n",
       "      <td>3159.5</td>\n",
       "      <td>1120.5</td>\n",
       "      <td>5519.5</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>622.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Temperature  Humidity  MQ7_analog  MQ9_analog  MG811_analog  \\\n",
       "0  ID_000001       28.975    74.475      2480.0      3476.5        1572.0   \n",
       "1  ID_000002       31.900    66.500      3813.0      2726.0        4145.0   \n",
       "2  ID_000003       31.675    60.015      2811.0      1563.5        4250.0   \n",
       "3  ID_000004       31.580    59.220      2844.0      1597.0        4310.0   \n",
       "4  ID_000005       31.690    62.030      3159.5      1120.5        5519.5   \n",
       "\n",
       "   MQ135_analog device_name     CO2  \n",
       "0        1997.0       alpha  585.75  \n",
       "1        3180.0       alpha  613.00  \n",
       "2        2708.5       alpha  616.50  \n",
       "3        2723.0       alpha  642.50  \n",
       "4        1219.0       alpha  622.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store IDs before feature engineering\n",
    "train_ids = train_data['ID'].copy()\n",
    "test_ids = test_data['ID'].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2: Handle missing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle important IDs\n",
    "required_ids = ['ID_007308', 'ID_007315', 'ID_007323', 'ID_007324', 'ID_007326']\n",
    "missing_ids = [id_value for id_value in required_ids if id_value not in test_data['ID'].values]\n",
    "\n",
    "if missing_ids:\n",
    "    new_rows = pd.DataFrame({'ID': missing_ids})\n",
    "    test_data = pd.concat([test_data, new_rows], ignore_index=True)\n",
    "    print(f\"Added missing IDs: {missing_ids}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3: Feature Engineering**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_features(df):\n",
    "    \n",
    "    df = df.copy()\n",
    "    sensor_cols = ['MQ7_analog', 'MQ9_analog', 'MG811_analog', 'MQ135_analog']\n",
    "    \n",
    "    # Basic sensor features\n",
    "    df['Sensor_mean'] = df[sensor_cols].mean(axis=1)\n",
    "    df['Sensor_std'] = df[sensor_cols].std(axis=1)\n",
    "    df['Sensor_median'] = df[sensor_cols].median(axis=1)\n",
    "    df['Sensor_max'] = df[sensor_cols].max(axis=1)\n",
    "    df['Sensor_min'] = df[sensor_cols].min(axis=1)\n",
    "    df['Sensor_range'] = df['Sensor_max'] - df['Sensor_min']\n",
    "    \n",
    "    # statistical features\n",
    "    df['Sensor_skew'] = df[sensor_cols].skew(axis=1)\n",
    "    df['Sensor_kurtosis'] = df[sensor_cols].kurtosis(axis=1)\n",
    "    \n",
    "    # Ratio features\n",
    "    for i in range(len(sensor_cols)):\n",
    "        for j in range(i+1, len(sensor_cols)):\n",
    "            ratio_name = f'ratio_{sensor_cols[i]}_{sensor_cols[j]}'\n",
    "            df[ratio_name] = df[sensor_cols[i]] / (df[sensor_cols[j]] + 1e-6)\n",
    "    \n",
    "    # Temperature Compensation with advanced scaling\n",
    "    temp_ref = 25.0\n",
    "    humidity_ref = 50.0\n",
    "    for col in sensor_cols:\n",
    "        # Temperature compensation\n",
    "        temp_factor = 1 + 0.02 * (df['Temperature'] - temp_ref)\n",
    "        # Humidity compensation\n",
    "        humid_factor = 1 + 0.01 * (df['Humidity'] - humidity_ref)\n",
    "        \n",
    "        df[f'{col}_temp_comp'] = df[col] * temp_factor\n",
    "        df[f'{col}_humid_comp'] = df[col] * humid_factor\n",
    "        df[f'{col}_full_comp'] = df[col] * temp_factor * humid_factor\n",
    "    \n",
    "    # Environmental Features\n",
    "    df['Temp_Humid_interaction'] = df['Temperature'] * df['Humidity']\n",
    "    df['Temp_Humid_ratio'] = df['Temperature'] / (df['Humidity'] + 1e-6)\n",
    "    df['Temp_squared'] = df['Temperature'] ** 2\n",
    "    df['Humid_squared'] = df['Humidity'] ** 2\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4: Apply Feature Engineering to Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating advanced features...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating advanced features...\")\n",
    "train_features = create_advanced_features(train_data.drop(['ID', 'device_name', 'CO2'], axis=1))\n",
    "test_features = create_advanced_features(test_data.drop(['ID', 'device_name'], axis=1))\n",
    "numeric_cols = train_features.select_dtypes(include=['float64', 'int64']).columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 5: Add Polynomial Features**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating polynomial features...\n",
      "Scaling features...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating polynomial features...\")\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly_features_train = poly.fit_transform(train_features[numeric_cols])\n",
    "poly_features_test = poly.transform(test_features[numeric_cols])\n",
    "\n",
    "feature_names = (\n",
    "    list(numeric_cols) + \n",
    "    [f\"poly_{i}\" for i in range(poly_features_train.shape[1] - len(numeric_cols))]\n",
    ")\n",
    "# Scale features\n",
    "print(\"Scaling features...\")\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(poly_features_train)\n",
    "test_scaled = scaler.transform(poly_features_test)\n",
    "y = train_data['CO2'].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 6: Hyperparameter Optimization with Optuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y, cv):\n",
    "    \"\"\"Optuna objective function for XGBoost optimization\"\"\"\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 5),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 5),\n",
    "        'tree_method': 'hist',\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    for train_idx, valid_idx in cv.split(X):\n",
    "        X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "        \n",
    "        model = XGBRegressor(**param)\n",
    "        model.fit(X_train, y_train,\n",
    "                 eval_set=[(X_valid, y_valid)],\n",
    "                 verbose=False)\n",
    "        \n",
    "        pred = model.predict(X_valid)\n",
    "        rmse = np.sqrt(mean_squared_error(y_valid, pred))\n",
    "        scores.append(rmse)\n",
    "    \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 7: Run Hyperparameter Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization\n",
    "print(\"Optimizing hyperparameters...\")\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(\n",
    "    lambda trial: objective(trial, X_scaled, y, cv),\n",
    "    n_trials=50,\n",
    "    timeout=3600  # 1 hour timeout\n",
    ")\n",
    "\n",
    "best_params = study.best_params\n",
    "best_params['tree_method'] = 'hist'\n",
    "best_params['random_state'] = 42\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 8: Train Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final model...\n",
      "Making predictions...\n",
      "Training completed! Best RMSE: 5.7107\n",
      "Submission saved with 1292 entries\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters from Optuna\n",
    "best_params = {\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.042000323432903566,\n",
    "    'n_estimators': 1128,\n",
    "    'min_child_weight': 3,\n",
    "    'subsample': 0.8388792014281559,\n",
    "    'colsample_bytree': 0.6496286198943079,\n",
    "    'gamma': 1.5039649063232274,\n",
    "    'reg_alpha': 4.097232713617798,\n",
    "    'reg_lambda': 2.3317882013391,\n",
    "    'max_bin': 318,\n",
    "    'grow_policy': 'depthwise',\n",
    "    'tree_method': 'hist',\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "print(\"Training final model...\")\n",
    "final_model = XGBRegressor(**best_params)\n",
    "final_model.fit(X_scaled, y)\n",
    "\n",
    "print(\"Making predictions...\")\n",
    "predictions = final_model.predict(test_scaled)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'CO2': predictions\n",
    "})\n",
    "\n",
    "mean_pred = predictions.mean()\n",
    "for id_value in required_ids:\n",
    "    if id_value not in submission['ID'].values:\n",
    "        submission = pd.concat([\n",
    "            submission,\n",
    "            pd.DataFrame({'ID': [id_value], 'CO2': [mean_pred]})\n",
    "        ])\n",
    "\n",
    "submission = submission.sort_values('ID').reset_index(drop=True)\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "submission_path = os.path.join('outputs', 'submission.csv')\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(\"Training completed! Best RMSE: 5.7107\")\n",
    "print(f\"Submission saved with {len(submission)} entries\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 9: Feature Importance Analysis**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Important Features:\n",
      "      feature  importance\n",
      "363  poly_327    0.046091\n",
      "447  poly_411    0.042238\n",
      "464  poly_428    0.038274\n",
      "459  poly_423    0.031643\n",
      "115   poly_79    0.027604\n",
      "337  poly_301    0.023573\n",
      "466  poly_430    0.022867\n",
      "628  poly_592    0.016849\n",
      "465  poly_429    0.015622\n",
      "561  poly_525    0.013871\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': final_model.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# Log top 10 important features\n",
    "print(\"\\nTop 10 Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28c58f3d93fa9a0742c3420978b3b6e732e223b6648923778d0e52a0a65fe59d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
