{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Applying advanced feature engineering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-01 00:08:16,829] A new study created in memory with name: no-name-b3e0206d-7269-4465-a8de-a2d7504decb7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying advanced scaling...\n",
      "Optimizing XGBoost parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-01 00:13:30,353] Trial 0 finished with value: 5.719788349794347 and parameters: {'n_estimators': 1277, 'max_depth': 9, 'learning_rate': 0.07935283764412371, 'subsample': 0.6337628809351206, 'colsample_bytree': 0.9206939514926019, 'min_child_weight': 6, 'gamma': 6.977049276451665e-06, 'reg_alpha': 0.313121159559002, 'reg_lambda': 0.08426785794280317}. Best is trial 0 with value: 5.719788349794347.\n",
      "[I 2025-02-01 00:18:51,247] Trial 1 finished with value: 5.584741334000084 and parameters: {'n_estimators': 2184, 'max_depth': 8, 'learning_rate': 0.03068285950841623, 'subsample': 0.7579104610561145, 'colsample_bytree': 0.8778307630983447, 'min_child_weight': 6, 'gamma': 4.058192028824901e-06, 'reg_alpha': 2.0080146877576325e-05, 'reg_lambda': 0.000838638146663865}. Best is trial 1 with value: 5.584741334000084.\n",
      "[I 2025-02-01 00:24:18,945] Trial 2 finished with value: 5.540298501077812 and parameters: {'n_estimators': 1920, 'max_depth': 9, 'learning_rate': 0.07086060438453877, 'subsample': 0.906516034624096, 'colsample_bytree': 0.7301890970677565, 'min_child_weight': 4, 'gamma': 3.155214022345081e-08, 'reg_alpha': 0.007776734316095919, 'reg_lambda': 5.022901283540327e-08}. Best is trial 2 with value: 5.540298501077812.\n",
      "[W 2025-02-01 07:44:02,739] Trial 3 failed with parameters: {'n_estimators': 2739, 'max_depth': 9, 'learning_rate': 0.01849429765210715, 'subsample': 0.7975321932623085, 'colsample_bytree': 0.6703259220989987, 'min_child_weight': 6, 'gamma': 0.2299927424296616, 'reg_alpha': 9.053684655917923e-05, 'reg_lambda': 0.030377957890866954} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_32176\\878677929.py\", line 119, in objective\n",
      "    model.fit(X_train, y_train,\n",
      "  File \"c:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\xgboost\\sklearn.py\", line 1108, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\xgboost\\core.py\", line 2101, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-02-01 07:44:02,938] Trial 3 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 131\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOptimizing XGBoost parameters...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    130\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 131\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[0;32m    133\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n\u001b[0;32m    134\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mBest parameters:\u001b[39m\u001b[39m\"\u001b[39m, best_params)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     _optimize(\n\u001b[0;32m    476\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    478\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    479\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    480\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    481\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    482\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    483\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    484\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    485\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[0;32m     64\u001b[0m             study,\n\u001b[0;32m     65\u001b[0m             func,\n\u001b[0;32m     66\u001b[0m             n_trials,\n\u001b[0;32m     67\u001b[0m             timeout,\n\u001b[0;32m     68\u001b[0m             catch,\n\u001b[0;32m     69\u001b[0m             callbacks,\n\u001b[0;32m     70\u001b[0m             gc_after_trial,\n\u001b[0;32m     71\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     72\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     73\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     74\u001b[0m         )\n\u001b[0;32m     75\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    198\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[2], line 119\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m    116\u001b[0m y_train, y_val \u001b[39m=\u001b[39m y[train_idx], y[val_idx]\n\u001b[0;32m    118\u001b[0m model \u001b[39m=\u001b[39m XGBRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m--> 119\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train,\n\u001b[0;32m    120\u001b[0m          eval_set\u001b[39m=\u001b[39;49m[(X_val, y_val)],\n\u001b[0;32m    121\u001b[0m          verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    123\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_val)\n\u001b[0;32m    124\u001b[0m rmse \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(mean_squared_error(y_val, preds))\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\xgboost\\sklearn.py:1108\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1105\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m model, metric, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m-> 1108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1109\u001b[0m     params,\n\u001b[0;32m   1110\u001b[0m     train_dmatrix,\n\u001b[0;32m   1111\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1112\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1113\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1114\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1115\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1116\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1117\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1118\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1119\u001b[0m     callbacks\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, iteration\u001b[39m=\u001b[39;49mi, fobj\u001b[39m=\u001b[39;49mobj)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         _LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\n\u001b[0;32m   2102\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, ctypes\u001b[39m.\u001b[39;49mc_int(iteration), dtrain\u001b[39m.\u001b[39;49mhandle\n\u001b[0;32m   2103\u001b[0m         )\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from scipy import stats\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_super_advanced_features(df):\n",
    "    \"\"\"Advanced feature engineering optimized for CO2 prediction\"\"\"\n",
    "    df = df.copy()\n",
    "    sensor_cols = ['MQ7_analog', 'MQ9_analog', 'MG811_analog', 'MQ135_analog']\n",
    "    \n",
    "    # 1. Sensor-specific weighted features\n",
    "    df['Sensor_weighted'] = (\n",
    "        df['MQ135_analog'] * 0.4 +    # MQ135 is most sensitive to CO2\n",
    "        df['MG811_analog'] * 0.3 +    # MG811 also specifically detects CO2\n",
    "        df['MQ7_analog'] * 0.15 +     # Less CO2-specific\n",
    "        df['MQ9_analog'] * 0.15       # Less CO2-specific\n",
    "    )\n",
    "    \n",
    "    # 2. Advanced Statistical Features\n",
    "    df['Sensor_mean'] = df[sensor_cols].mean(axis=1)\n",
    "    df['Sensor_std'] = df[sensor_cols].std(axis=1)\n",
    "    df['Sensor_median'] = df[sensor_cols].median(axis=1)\n",
    "    df['Sensor_max'] = df[sensor_cols].max(axis=1)\n",
    "    df['Sensor_min'] = df[sensor_cols].min(axis=1)\n",
    "    df['Sensor_range'] = df['Sensor_max'] - df['Sensor_min']\n",
    "    df['Sensor_skew'] = df[sensor_cols].skew(axis=1)\n",
    "    df['Sensor_kurt'] = df[sensor_cols].kurtosis(axis=1)\n",
    "    \n",
    "    # 3. Temperature Compensation\n",
    "    temp_ref = 25.0\n",
    "    for col in sensor_cols:\n",
    "        temp_factor = 1 + 0.02 * (df['Temperature'] - temp_ref)\n",
    "        df[f'{col}_temp_comp'] = df[col] * temp_factor\n",
    "    \n",
    "    # 4. Advanced Ratio Features\n",
    "    for i, col1 in enumerate(sensor_cols):\n",
    "        for col2 in sensor_cols[i+1:]:\n",
    "            df[f'{col1}_{col2}_ratio'] = df[col1] / (df[col2] + 1e-6)\n",
    "            df[f'{col1}_{col2}_diff'] = df[col1] - df[col2]\n",
    "            df[f'{col1}_{col2}_product'] = df[col1] * df[col2]\n",
    "    \n",
    "    # 5. Environmental Features\n",
    "    df['Temp_Humid_interaction'] = df['Temperature'] * df['Humidity']\n",
    "    df['Temp_Humid_ratio'] = df['Temperature'] / (df['Humidity'] + 1e-6)\n",
    "    \n",
    "    # 6. Non-linear Transformations\n",
    "    for col in sensor_cols:\n",
    "        df[f'{col}_log'] = np.log1p(df[col])\n",
    "        df[f'{col}_sqrt'] = np.sqrt(df[col])\n",
    "        df[f'{col}_squared'] = df[col] ** 2\n",
    "    \n",
    "    # 7. Rolling Features\n",
    "    windows = [2, 3, 5]\n",
    "    for window in windows:\n",
    "        df[f'weighted_ma_{window}'] = df['Sensor_weighted'].rolling(window, min_periods=1).mean()\n",
    "        df[f'weighted_std_{window}'] = df['Sensor_weighted'].rolling(window, min_periods=1).std()\n",
    "        \n",
    "    return df\n",
    "\n",
    "def optimize_xgb_params(trial):\n",
    "    return {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 3000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "# Load and prepare data\n",
    "print(\"Loading data...\")\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "sample_submission = pd.read_csv(\"SampleSubmission.csv\")\n",
    "\n",
    "# Remove unnecessary columns\n",
    "columns_to_drop = ['ID', 'device_name']\n",
    "train_data = train_data.drop(columns=columns_to_drop, errors='ignore')\n",
    "test_data = test_data.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Apply advanced feature engineering\n",
    "print(\"Applying advanced feature engineering...\")\n",
    "train_data = create_super_advanced_features(train_data)\n",
    "test_data = create_super_advanced_features(test_data)\n",
    "\n",
    "# Select features\n",
    "features = [col for col in train_data.columns if col != 'CO2']\n",
    "\n",
    "# Prepare data\n",
    "X = train_data[features].values\n",
    "y = train_data['CO2'].values\n",
    "\n",
    "# Advanced scaling\n",
    "print(\"Applying advanced scaling...\")\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Hyperparameter optimization\n",
    "def objective(trial):\n",
    "    params = optimize_xgb_params(trial)\n",
    "    cv_scores = []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_scaled):\n",
    "        X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train,\n",
    "                 eval_set=[(X_val, y_val)],\n",
    "                 verbose=False)\n",
    "        \n",
    "        preds = model.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "        cv_scores.append(rmse)\n",
    "    \n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "print(\"Optimizing XGBoost parameters...\")\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"\\nBest parameters:\", best_params)\n",
    "\n",
    "# Create multiple XGBoost models with different seeds\n",
    "models = [\n",
    "    XGBRegressor(**best_params, random_state=42),\n",
    "    XGBRegressor(**best_params, random_state=24),\n",
    "    XGBRegressor(\n",
    "        **{**best_params,\n",
    "           'n_estimators': int(best_params['n_estimators'] * 1.2),\n",
    "           'learning_rate': best_params['learning_rate'] * 0.8\n",
    "        },\n",
    "        random_state=100\n",
    "    )\n",
    "]\n",
    "\n",
    "# Cross-validation\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "oof_preds = np.zeros((len(X_scaled), len(models)))\n",
    "test_preds = np.zeros((len(test_data), len(models)))\n",
    "\n",
    "print(\"\\nStarting cross-validation...\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        model.fit(X_train, y_train,\n",
    "                 eval_set=[(X_val, y_val)],\n",
    "                 verbose=False)\n",
    "        \n",
    "        oof_preds[val_idx, i] = model.predict(X_val)\n",
    "        test_preds[:, i] += model.predict(scaler.transform(test_data[features])) / n_splits\n",
    "        \n",
    "        fold_rmse = np.sqrt(mean_squared_error(y_val, oof_preds[val_idx, i]))\n",
    "        print(f\"Model {i+1} RMSE: {fold_rmse:.4f}\")\n",
    "\n",
    "# Calculate optimal weights based on OOF performance\n",
    "model_rmses = []\n",
    "for i in range(len(models)):\n",
    "    rmse = np.sqrt(mean_squared_error(y, oof_preds[:, i]))\n",
    "    model_rmses.append(rmse)\n",
    "\n",
    "weights = 1 / np.array(model_rmses)\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "# Final weighted prediction\n",
    "final_predictions = np.average(test_preds, weights=weights, axis=1)\n",
    "\n",
    "# Create submission file\n",
    "print(\"\\nCreating submission file...\")\n",
    "sample_submission['CO2'] = final_predictions\n",
    "sample_submission.to_csv('submission_xgboost_advanced.csv', index=False)\n",
    "\n",
    "print(\"\\nDone! Check 'submission_xgboost_advanced.csv' for predictions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28c58f3d93fa9a0742c3420978b3b6e732e223b6648923778d0e52a0a65fe59d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
