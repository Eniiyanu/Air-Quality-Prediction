{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Applying advanced feature engineering...\n",
      "Applying advanced scaling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 20:13:16,810] A new study created in memory with name: no-name-bae09b50-e62a-465c-97fa-110a07438e5e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 20:50:52,072] Trial 0 finished with value: 9.753959433505662 and parameters: {'n_estimators': 921, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 0 with value: 9.753959433505662.\n",
      "[I 2025-01-31 20:52:31,061] Trial 1 finished with value: 11.510232572529542 and parameters: {'n_estimators': 511, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 0 with value: 9.753959433505662.\n",
      "[I 2025-01-31 20:52:59,679] Trial 2 finished with value: 7.44303317517569 and parameters: {'n_estimators': 111, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 20:59:12,373] Trial 3 finished with value: 7.878989630512512 and parameters: {'n_estimators': 799, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:01:51,541] Trial 4 finished with value: 12.507432561786427 and parameters: {'n_estimators': 664, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:04:35,301] Trial 5 finished with value: 7.52562129548639 and parameters: {'n_estimators': 679, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:06:52,933] Trial 6 finished with value: 8.714509711556465 and parameters: {'n_estimators': 823, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:12:41,615] Trial 7 finished with value: 13.510121318187952 and parameters: {'n_estimators': 269, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:16:29,910] Trial 8 finished with value: 12.210533374780955 and parameters: {'n_estimators': 152, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:19:31,677] Trial 9 finished with value: 10.234727918064527 and parameters: {'n_estimators': 360, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:20:50,262] Trial 10 finished with value: 8.658147445199406 and parameters: {'n_estimators': 111, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:25:31,171] Trial 11 finished with value: 7.578506848229077 and parameters: {'n_estimators': 543, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:29:22,897] Trial 12 finished with value: 7.538258438107379 and parameters: {'n_estimators': 412, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:34:21,501] Trial 13 finished with value: 8.754933564189574 and parameters: {'n_estimators': 674, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:43:49,001] Trial 14 finished with value: 7.517958173764763 and parameters: {'n_estimators': 999, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:51:59,695] Trial 15 finished with value: 8.049652795809752 and parameters: {'n_estimators': 979, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:53:33,767] Trial 16 finished with value: 9.539933850988739 and parameters: {'n_estimators': 251, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:57:01,296] Trial 17 finished with value: 8.066475945216721 and parameters: {'n_estimators': 436, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[W 2025-01-31 22:58:33,311] Trial 18 failed with parameters: {'n_estimators': 846, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': None} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24256\\3944323049.py\", line 94, in objective\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"c:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 487, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"c:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 189, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"c:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "KeyboardInterrupt\n",
      "[W 2025-01-31 22:58:33,404] Trial 18 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 133\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39m# Hyperparameter Optimization\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOptimizing hyperparameters...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m best_params \u001b[39m=\u001b[39m optimize_hyperparameters(X_scaled, y)\n\u001b[0;32m    135\u001b[0m \u001b[39m# Initialize models\u001b[39;00m\n\u001b[0;32m    136\u001b[0m models \u001b[39m=\u001b[39m {\n\u001b[0;32m    137\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mRandomForest\u001b[39m\u001b[39m'\u001b[39m: RandomForestRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbest_params),\n\u001b[0;32m    138\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mXGBoost\u001b[39m\u001b[39m'\u001b[39m: XGBRegressor(n_estimators\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m),\n\u001b[0;32m    139\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mLightGBM\u001b[39m\u001b[39m'\u001b[39m: LGBMRegressor(n_estimators\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m),\n\u001b[0;32m    140\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mMLP\u001b[39m\u001b[39m'\u001b[39m: MLPRegressor(hidden_layer_sizes\u001b[39m=\u001b[39m(\u001b[39m100\u001b[39m, \u001b[39m50\u001b[39m), max_iter\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m    141\u001b[0m }\n",
      "Cell \u001b[1;32mIn[2], line 100\u001b[0m, in \u001b[0;36moptimize_hyperparameters\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(scores)\n\u001b[0;32m     99\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 100\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[0;32m    101\u001b[0m \u001b[39mreturn\u001b[39;00m study\u001b[39m.\u001b[39mbest_params\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     _optimize(\n\u001b[0;32m    476\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    478\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    479\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    480\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    481\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    482\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    483\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    484\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    485\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[0;32m     64\u001b[0m             study,\n\u001b[0;32m     65\u001b[0m             func,\n\u001b[0;32m     66\u001b[0m             n_trials,\n\u001b[0;32m     67\u001b[0m             timeout,\n\u001b[0;32m     68\u001b[0m             catch,\n\u001b[0;32m     69\u001b[0m             callbacks,\n\u001b[0;32m     70\u001b[0m             gc_after_trial,\n\u001b[0;32m     71\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     72\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     73\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     74\u001b[0m         )\n\u001b[0;32m     75\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    198\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[2], line 94\u001b[0m, in \u001b[0;36moptimize_hyperparameters.<locals>.objective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     92\u001b[0m X_train, X_val \u001b[39m=\u001b[39m X[train_idx], X[val_idx]\n\u001b[0;32m     93\u001b[0m y_train, y_val \u001b[39m=\u001b[39m y[train_idx], y[val_idx]\n\u001b[1;32m---> 94\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     95\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_val)\n\u001b[0;32m     96\u001b[0m scores\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39msqrt(mean_squared_error(y_val, y_pred)))\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    488\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    489\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    490\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    491\u001b[0m )(\n\u001b[0;32m    492\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    493\u001b[0m         t,\n\u001b[0;32m    494\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    495\u001b[0m         X,\n\u001b[0;32m    496\u001b[0m         y,\n\u001b[0;32m    497\u001b[0m         sample_weight,\n\u001b[0;32m    498\u001b[0m         i,\n\u001b[0;32m    499\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    500\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    501\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    502\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    503\u001b[0m         missing_values_in_feature_mask\u001b[39m=\u001b[39;49mmissing_values_in_feature_mask,\n\u001b[0;32m    504\u001b[0m     )\n\u001b[0;32m    505\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    506\u001b[0m )\n\u001b[0;32m    508\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     tree\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    190\u001b[0m         X,\n\u001b[0;32m    191\u001b[0m         y,\n\u001b[0;32m    192\u001b[0m         sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight,\n\u001b[0;32m    193\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    194\u001b[0m         missing_values_in_feature_mask\u001b[39m=\u001b[39;49mmissing_values_in_feature_mask,\n\u001b[0;32m    195\u001b[0m     )\n\u001b[0;32m    196\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     tree\u001b[39m.\u001b[39m_fit(\n\u001b[0;32m    198\u001b[0m         X,\n\u001b[0;32m    199\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m         missing_values_in_feature_mask\u001b[39m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    203\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\USER\\Documents\\Contest\\Zindi-Air-Prediction\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.base import clone\n",
    "from scipy import stats\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Advanced Feature Engineering\n",
    "def create_super_advanced_features(df):\n",
    "    \"\"\"Advanced feature engineering with sophisticated transformations\"\"\"\n",
    "    df = df.copy()\n",
    "    sensor_cols = ['MQ7_analog', 'MQ9_analog', 'MG811_analog', 'MQ135_analog']\n",
    "    \n",
    "    # 1. Advanced Statistical Features\n",
    "    df['Sensor_mean'] = df[sensor_cols].mean(axis=1)\n",
    "    df['Sensor_std'] = df[sensor_cols].std(axis=1)\n",
    "    df['Sensor_median'] = df[sensor_cols].median(axis=1)\n",
    "    df['Sensor_max'] = df[sensor_cols].max(axis=1)\n",
    "    df['Sensor_min'] = df[sensor_cols].min(axis=1)\n",
    "    df['Sensor_range'] = df['Sensor_max'] - df['Sensor_min']\n",
    "    df['Sensor_skew'] = df[sensor_cols].skew(axis=1)\n",
    "    df['Sensor_kurt'] = df[sensor_cols].kurtosis(axis=1)\n",
    "    \n",
    "    # 2. Advanced Ratio Features\n",
    "    for i, col1 in enumerate(sensor_cols):\n",
    "        for col2 in sensor_cols[i+1:]:\n",
    "            df[f'{col1}_{col2}_ratio'] = df[col1] / (df[col2] + 1e-6)\n",
    "            df[f'{col1}_{col2}_diff'] = df[col1] - df[col2]\n",
    "            df[f'{col1}_{col2}_product'] = df[col1] * df[col2]\n",
    "            df[f'{col1}_{col2}_sum'] = df[col1] + df[col2]\n",
    "            df[f'{col1}_{col2}_mean'] = (df[col1] + df[col2]) / 2\n",
    "    \n",
    "    # 3. Environmental Interaction Features\n",
    "    df['Temp_Humid_interaction'] = df['Temperature'] * df['Humidity']\n",
    "    df['Temp_Humid_ratio'] = df['Temperature'] / (df['Humidity'] + 1e-6)\n",
    "    df['Temp_Humid_sum'] = df['Temperature'] + df['Humidity']\n",
    "    df['Temp_Humid_diff'] = df['Temperature'] - df['Humidity']\n",
    "    \n",
    "    # 4. Polynomial Features\n",
    "    degrees = [2, 3, 0.5]\n",
    "    for deg in degrees:\n",
    "        df[f'Temperature_power_{deg}'] = df['Temperature'] ** deg\n",
    "        df[f'Humidity_power_{deg}'] = df['Humidity'] ** deg\n",
    "        df[f'Sensor_mean_power_{deg}'] = df['Sensor_mean'] ** deg\n",
    "    \n",
    "    # 5. Advanced Transformations\n",
    "    for col in sensor_cols:\n",
    "        df[f'{col}_log'] = np.log1p(df[col])\n",
    "        df[f'{col}_sqrt'] = np.sqrt(df[col])\n",
    "        df[f'{col}_squared'] = df[col] ** 2\n",
    "        df[f'{col}_cubed'] = df[col] ** 3\n",
    "    \n",
    "    # 6. Advanced Aggregations\n",
    "    df['Sensor_geometric_mean'] = stats.gmean(df[sensor_cols] + 1, axis=1)\n",
    "    df['Sensor_harmonic_mean'] = stats.hmean(df[sensor_cols] + 1, axis=1)\n",
    "    \n",
    "    # 7. Advanced Interactions\n",
    "    df['MQ7_MQ135_temp_ratio'] = df['MQ7_analog'] * df['Temperature'] / (df['MQ135_analog'] + 1e-6)\n",
    "    df['MQ9_MG811_humid_ratio'] = df['MQ9_analog'] * df['Humidity'] / (df['MG811_analog'] + 1e-6)\n",
    "    \n",
    "    # 8. Rolling Features (if temporal nature exists)\n",
    "    window_sizes = [2, 3, 4]\n",
    "    for window in window_sizes:\n",
    "        df[f'rolling_mean_{window}'] = df['Sensor_mean'].rolling(window, min_periods=1).mean()\n",
    "        df[f'rolling_std_{window}'] = df['Sensor_mean'].rolling(window, min_periods=1).std()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Hyperparameter Optimization with Optuna\n",
    "def optimize_hyperparameters(X, y):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),  # Only valid values\n",
    "            'random_state': 42\n",
    "        }\n",
    "        model = RandomForestRegressor(**params)\n",
    "        scores = []\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for train_idx, val_idx in kf.split(X):\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_val)\n",
    "            scores.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "        return np.mean(scores)\n",
    "    \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=25)\n",
    "    return study.best_params\n",
    "\n",
    "# Load and prepare data\n",
    "print(\"Loading data...\")\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "sample_submission = pd.read_csv(\"SampleSubmission.csv\")\n",
    "\n",
    "# Remove unnecessary columns\n",
    "columns_to_drop = ['ID', 'device_name']\n",
    "train_data = train_data.drop(columns=columns_to_drop, errors='ignore')\n",
    "test_data = test_data.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Apply super advanced feature engineering\n",
    "print(\"Applying advanced feature engineering...\")\n",
    "train_data = create_super_advanced_features(train_data)\n",
    "test_data = create_super_advanced_features(test_data)\n",
    "\n",
    "# Select features (excluding target)\n",
    "features = [col for col in train_data.columns if col != 'CO2']\n",
    "\n",
    "# Prepare data\n",
    "X = train_data[features].values\n",
    "y = train_data['CO2'].values\n",
    "\n",
    "# Advanced scaling\n",
    "print(\"Applying advanced scaling...\")\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "print(\"Optimizing hyperparameters...\")\n",
    "best_params = optimize_hyperparameters(X_scaled, y)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'RandomForest': RandomForestRegressor(**best_params),\n",
    "    'XGBoost': XGBRegressor(n_estimators=1000, learning_rate=0.05, random_state=42),\n",
    "    'LightGBM': LGBMRegressor(n_estimators=1000, learning_rate=0.05, random_state=42),\n",
    "    'MLP': MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "# Initialize K-fold\n",
    "n_splits = 5\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Arrays to store predictions\n",
    "oof_predictions = {model_name: np.zeros(len(X_scaled)) for model_name in models}\n",
    "test_predictions = {model_name: np.zeros(len(test_data)) for model_name in models}\n",
    "\n",
    "# Cross-validation loop\n",
    "print(\"Starting cross-validation...\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled, pd.cut(y, bins=10, labels=False))):\n",
    "    print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        oof_predictions[model_name][val_idx] = model.predict(X_val)\n",
    "        test_predictions[model_name] += model.predict(scaler.transform(test_data[features])) / n_splits\n",
    "        \n",
    "        # Print fold scores\n",
    "        print(f\"{model_name} RMSE: {np.sqrt(mean_squared_error(y_val, oof_predictions[model_name][val_idx])):.4f}\")\n",
    "\n",
    "# Ensemble predictions\n",
    "final_predictions = np.mean([test_predictions[model_name] for model_name in models], axis=0)\n",
    "\n",
    "# Create submission file\n",
    "print(\"\\nCreating submission file...\")\n",
    "sample_submission['CO2'] = final_predictions\n",
    "sample_submission.to_csv('submission_ensemble.csv', index=False)\n",
    "\n",
    "print(\"\\nDone! Check 'submission_ensemble.csv' for predictions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28c58f3d93fa9a0742c3420978b3b6e732e223b6648923778d0e52a0a65fe59d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
