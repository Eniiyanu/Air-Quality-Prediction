{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Applying advanced feature engineering...\n",
      "Applying advanced scaling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 20:13:16,810] A new study created in memory with name: no-name-bae09b50-e62a-465c-97fa-110a07438e5e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 20:50:52,072] Trial 0 finished with value: 9.753959433505662 and parameters: {'n_estimators': 921, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 0 with value: 9.753959433505662.\n",
      "[I 2025-01-31 20:52:31,061] Trial 1 finished with value: 11.510232572529542 and parameters: {'n_estimators': 511, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 0 with value: 9.753959433505662.\n",
      "[I 2025-01-31 20:52:59,679] Trial 2 finished with value: 7.44303317517569 and parameters: {'n_estimators': 111, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 20:59:12,373] Trial 3 finished with value: 7.878989630512512 and parameters: {'n_estimators': 799, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:01:51,541] Trial 4 finished with value: 12.507432561786427 and parameters: {'n_estimators': 664, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:04:35,301] Trial 5 finished with value: 7.52562129548639 and parameters: {'n_estimators': 679, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:06:52,933] Trial 6 finished with value: 8.714509711556465 and parameters: {'n_estimators': 823, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:12:41,615] Trial 7 finished with value: 13.510121318187952 and parameters: {'n_estimators': 269, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:16:29,910] Trial 8 finished with value: 12.210533374780955 and parameters: {'n_estimators': 152, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:19:31,677] Trial 9 finished with value: 10.234727918064527 and parameters: {'n_estimators': 360, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:20:50,262] Trial 10 finished with value: 8.658147445199406 and parameters: {'n_estimators': 111, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:25:31,171] Trial 11 finished with value: 7.578506848229077 and parameters: {'n_estimators': 543, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:29:22,897] Trial 12 finished with value: 7.538258438107379 and parameters: {'n_estimators': 412, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:34:21,501] Trial 13 finished with value: 8.754933564189574 and parameters: {'n_estimators': 674, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:43:49,001] Trial 14 finished with value: 7.517958173764763 and parameters: {'n_estimators': 999, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:51:59,695] Trial 15 finished with value: 8.049652795809752 and parameters: {'n_estimators': 979, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:53:33,767] Trial 16 finished with value: 9.539933850988739 and parameters: {'n_estimators': 251, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n",
      "[I 2025-01-31 21:57:01,296] Trial 17 finished with value: 8.066475945216721 and parameters: {'n_estimators': 436, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 2 with value: 7.44303317517569.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.base import clone\n",
    "from scipy import stats\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Advanced Feature Engineering\n",
    "def create_super_advanced_features(df):\n",
    "    \"\"\"Advanced feature engineering with sophisticated transformations\"\"\"\n",
    "    df = df.copy()\n",
    "    sensor_cols = ['MQ7_analog', 'MQ9_analog', 'MG811_analog', 'MQ135_analog']\n",
    "    \n",
    "    # 1. Advanced Statistical Features\n",
    "    df['Sensor_mean'] = df[sensor_cols].mean(axis=1)\n",
    "    df['Sensor_std'] = df[sensor_cols].std(axis=1)\n",
    "    df['Sensor_median'] = df[sensor_cols].median(axis=1)\n",
    "    df['Sensor_max'] = df[sensor_cols].max(axis=1)\n",
    "    df['Sensor_min'] = df[sensor_cols].min(axis=1)\n",
    "    df['Sensor_range'] = df['Sensor_max'] - df['Sensor_min']\n",
    "    df['Sensor_skew'] = df[sensor_cols].skew(axis=1)\n",
    "    df['Sensor_kurt'] = df[sensor_cols].kurtosis(axis=1)\n",
    "    \n",
    "    # 2. Advanced Ratio Features\n",
    "    for i, col1 in enumerate(sensor_cols):\n",
    "        for col2 in sensor_cols[i+1:]:\n",
    "            df[f'{col1}_{col2}_ratio'] = df[col1] / (df[col2] + 1e-6)\n",
    "            df[f'{col1}_{col2}_diff'] = df[col1] - df[col2]\n",
    "            df[f'{col1}_{col2}_product'] = df[col1] * df[col2]\n",
    "            df[f'{col1}_{col2}_sum'] = df[col1] + df[col2]\n",
    "            df[f'{col1}_{col2}_mean'] = (df[col1] + df[col2]) / 2\n",
    "    \n",
    "    # 3. Environmental Interaction Features\n",
    "    df['Temp_Humid_interaction'] = df['Temperature'] * df['Humidity']\n",
    "    df['Temp_Humid_ratio'] = df['Temperature'] / (df['Humidity'] + 1e-6)\n",
    "    df['Temp_Humid_sum'] = df['Temperature'] + df['Humidity']\n",
    "    df['Temp_Humid_diff'] = df['Temperature'] - df['Humidity']\n",
    "    \n",
    "    # 4. Polynomial Features\n",
    "    degrees = [2, 3, 0.5]\n",
    "    for deg in degrees:\n",
    "        df[f'Temperature_power_{deg}'] = df['Temperature'] ** deg\n",
    "        df[f'Humidity_power_{deg}'] = df['Humidity'] ** deg\n",
    "        df[f'Sensor_mean_power_{deg}'] = df['Sensor_mean'] ** deg\n",
    "    \n",
    "    # 5. Advanced Transformations\n",
    "    for col in sensor_cols:\n",
    "        df[f'{col}_log'] = np.log1p(df[col])\n",
    "        df[f'{col}_sqrt'] = np.sqrt(df[col])\n",
    "        df[f'{col}_squared'] = df[col] ** 2\n",
    "        df[f'{col}_cubed'] = df[col] ** 3\n",
    "    \n",
    "    # 6. Advanced Aggregations\n",
    "    df['Sensor_geometric_mean'] = stats.gmean(df[sensor_cols] + 1, axis=1)\n",
    "    df['Sensor_harmonic_mean'] = stats.hmean(df[sensor_cols] + 1, axis=1)\n",
    "    \n",
    "    # 7. Advanced Interactions\n",
    "    df['MQ7_MQ135_temp_ratio'] = df['MQ7_analog'] * df['Temperature'] / (df['MQ135_analog'] + 1e-6)\n",
    "    df['MQ9_MG811_humid_ratio'] = df['MQ9_analog'] * df['Humidity'] / (df['MG811_analog'] + 1e-6)\n",
    "    \n",
    "    # 8. Rolling Features (if temporal nature exists)\n",
    "    window_sizes = [2, 3, 4]\n",
    "    for window in window_sizes:\n",
    "        df[f'rolling_mean_{window}'] = df['Sensor_mean'].rolling(window, min_periods=1).mean()\n",
    "        df[f'rolling_std_{window}'] = df['Sensor_mean'].rolling(window, min_periods=1).std()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Hyperparameter Optimization with Optuna\n",
    "def optimize_hyperparameters(X, y):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),  # Only valid values\n",
    "            'random_state': 42\n",
    "        }\n",
    "        model = RandomForestRegressor(**params)\n",
    "        scores = []\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for train_idx, val_idx in kf.split(X):\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_val)\n",
    "            scores.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "        return np.mean(scores)\n",
    "    \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=25)\n",
    "    return study.best_params\n",
    "\n",
    "# Load and prepare data\n",
    "print(\"Loading data...\")\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "sample_submission = pd.read_csv(\"SampleSubmission.csv\")\n",
    "\n",
    "# Remove unnecessary columns\n",
    "columns_to_drop = ['ID', 'device_name']\n",
    "train_data = train_data.drop(columns=columns_to_drop, errors='ignore')\n",
    "test_data = test_data.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Apply super advanced feature engineering\n",
    "print(\"Applying advanced feature engineering...\")\n",
    "train_data = create_super_advanced_features(train_data)\n",
    "test_data = create_super_advanced_features(test_data)\n",
    "\n",
    "# Select features (excluding target)\n",
    "features = [col for col in train_data.columns if col != 'CO2']\n",
    "\n",
    "# Prepare data\n",
    "X = train_data[features].values\n",
    "y = train_data['CO2'].values\n",
    "\n",
    "# Advanced scaling\n",
    "print(\"Applying advanced scaling...\")\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "print(\"Optimizing hyperparameters...\")\n",
    "best_params = optimize_hyperparameters(X_scaled, y)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'RandomForest': RandomForestRegressor(**best_params),\n",
    "    'XGBoost': XGBRegressor(n_estimators=1000, learning_rate=0.05, random_state=42),\n",
    "    'LightGBM': LGBMRegressor(n_estimators=1000, learning_rate=0.05, random_state=42),\n",
    "    'MLP': MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "# Initialize K-fold\n",
    "n_splits = 5\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Arrays to store predictions\n",
    "oof_predictions = {model_name: np.zeros(len(X_scaled)) for model_name in models}\n",
    "test_predictions = {model_name: np.zeros(len(test_data)) for model_name in models}\n",
    "\n",
    "# Cross-validation loop\n",
    "print(\"Starting cross-validation...\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled, pd.cut(y, bins=10, labels=False))):\n",
    "    print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        oof_predictions[model_name][val_idx] = model.predict(X_val)\n",
    "        test_predictions[model_name] += model.predict(scaler.transform(test_data[features])) / n_splits\n",
    "        \n",
    "        # Print fold scores\n",
    "        print(f\"{model_name} RMSE: {np.sqrt(mean_squared_error(y_val, oof_predictions[model_name][val_idx])):.4f}\")\n",
    "\n",
    "# Ensemble predictions\n",
    "final_predictions = np.mean([test_predictions[model_name] for model_name in models], axis=0)\n",
    "\n",
    "# Create submission file\n",
    "print(\"\\nCreating submission file...\")\n",
    "sample_submission['CO2'] = final_predictions\n",
    "sample_submission.to_csv('submission_ensemble.csv', index=False)\n",
    "\n",
    "print(\"\\nDone! Check 'submission_ensemble.csv' for predictions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28c58f3d93fa9a0742c3420978b3b6e732e223b6648923778d0e52a0a65fe59d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
